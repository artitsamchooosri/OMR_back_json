{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image,ImageEnhance\n",
    "from imutils.perspective import four_point_transform\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_canny(image, sigma=0.4):\n",
    "\t# compute the median of the single channel pixel intensities\n",
    "\tv = np.median(image)\n",
    "\t# apply automatic Canny edge detection using the computed median\n",
    "\tlower = int(max(0, (1.0 - sigma) * v))\n",
    "\tupper = int(min(255, (1.0 + sigma) * v))\n",
    "\tedged = cv2.Canny(image, lower, upper)\n",
    "\t# return the edged image\n",
    "\treturn edged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathImage = r\"data\\omr_line.v2i.yolov7pytorch\\train\\images\\310377047_465921045601836_3357657464690243685_n_jpg.rf.32b8bfbd56bde205a8bdec2fa9460b1a.jpg\"\n",
    "\n",
    "img_ori=Image.open(pathImage)\n",
    "contrast_enhancer = ImageEnhance.Contrast(img_ori)\n",
    "pil_enhanced_image = contrast_enhancer.enhance(2)\n",
    "enhanced_image = np.asarray(pil_enhanced_image)\n",
    "con = np.zeros_like(img_ori)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "image_oricoppy=enhanced_image.copy()\n",
    "enhanced_image = cv2.morphologyEx(enhanced_image, cv2.MORPH_CLOSE, kernel, iterations= 3)\n",
    "\n",
    "\n",
    "imgGray = cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2GRAY)\n",
    "imgBlur = cv2.GaussianBlur(imgGray, (5, 5), 1)\n",
    "imgThreshold = auto_canny(imgBlur)\n",
    "img = Image.fromarray(np.uint8(imgThreshold))\n",
    "img.show()\n",
    "kernel = np.ones((5, 5))\n",
    "imgDial = cv2.dilate(imgThreshold, kernel, iterations=2)\n",
    "imgThreshold = cv2.erode(imgDial, kernel, iterations=1)\n",
    "img2 = Image.fromarray(np.uint8(imgThreshold))\n",
    "img2.show()\n",
    "contours, hierarchy = cv2.findContours(imgThreshold, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "page = sorted(contours, key=cv2.contourArea, reverse=True)[:5]\n",
    "#con = cv2.drawContours(con, page, -1, (0, 255, 255), 3)\n",
    "for contour in contours:\n",
    "    peri = cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, 0.05 * peri, True)\n",
    "    if len(approx) == 4:\n",
    "        doc_cnts = approx\n",
    "        break\n",
    "warped = four_point_transform(image_oricoppy, doc_cnts.reshape(4, 2))\n",
    "img3 = Image.fromarray(np.uint8(warped))\n",
    "img3.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf3d5ae132344286b182a19bc4934bf660f140e94b2b536307aac6c0d873b784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
